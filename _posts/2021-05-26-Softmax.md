---
layout: post
mathjax: true
title:  "Dense layer with backpropagation in C++, part 5"
date:   2021-05-21 00:00:00 +0000
categories: github jekyll
---

### Adding Softmax layer

In this post I'll modify the previous example adding Softmax layer.

Softmax function for N-dimentional input vector is defined as

$$ \sigma (x)_{i} = \frac e^{x_{i}} \sum_{i=0}^(N-1) e^{x_{i}} $$



Previous example can be found at ["Dense layer with backpropagation and sigmoid activation in C++"] [previous_post]

[previous_post]: https://alexgl-github.github.io/github/jekyll/2021/05/21/Sigmoid.html
[python_source_code]:  https://github.com/alexgl-github/alexgl-github.github.io/tree/main/src/dense5.py
[cpp_source_code]:  https://github.com/alexgl-github/alexgl-github.github.io/tree/main/src/dense5.cpp

