---
layout: post
mathjax: true
title:  "Dense layer with backpropagation in C++, part 4"
date:   2021-05-21 00:00:00 +0000
categories: github jekyll
---

### Dense layer with backpropagation and sigmoid activation in C++, part 4

In this post I'll modify the previous example adding Sigmoid activation layer.

Previous example can be found at ["Dense layer with backpropagation in C++, part 3"] [previous_post]

Forward path for Sigmoid layer is sigmoid function

$$ \sigma(x) = \frac {1} {1 + e^{-x}} $$

For backpropagation we'll need to find sigmoid derivative $$\frac{\partial{\sigma{(x)}} \partial{x}}


$$
1. f(x) = \frac{1 \sigma (x)}
2. f(x) = 1 + e^{-x}
$$

Taking derviatives

1.

$$
\frac{1 \sigma{(x)}} = \frac{\partial\{\sigma{(x)}^{-1} \partial{x}} = - \frac{1 \sigma{(x)}^2} * \frac{\partial{\sigma{(x)}} \partial{x}}
$$

2.

$$
\frac{\partial{1 + e^{-x}} \partial{x}} = - e^{-x} = 1 - f(x) = 1 - \frac{1 \sigma{(x)}} = \frac{{\sigma (x) - 1} \sigma (x)}
$$

After making 1. and 2. equal, and simplifying

$$
- \frac{1 \sigma{(x)}^2} * \frac{\partial{\sigma{(x)}} \partial{x}} = \frac{{\sigma (x) - 1} \sigma (x)}

\partial{\sigma{(x)}} \partial{x} = \sigma (x) * (1 - \sigma (x))

$$


[previous_post]:  https://alexgl-github.github.io/github/jekyll/2021/04/28/Dense_layer_with_bias.html
[python_source_code]:  https://github.com/alexgl-github/alexgl-github.github.io/tree/main/src/dense4.py
[cpp_source_code]:  https://github.com/alexgl-github/alexgl-github.github.io/tree/main/src/dense4.cpp
